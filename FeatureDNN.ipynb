{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import img_to_array, load_img, array_to_img\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data (891, 192) (891, 99)\n",
      "Validated Data (99, 192) (99, 99)\n",
      "Test Data (594, 192)\n"
     ]
    }
   ],
   "source": [
    "train_feature_data = pd.read_csv(\"train.csv\")\n",
    "test_feature_data = pd.read_csv(\"test.csv\")\n",
    "\n",
    "ID = train_feature_data.pop(\"id\")\n",
    "\n",
    "train_labels = train_feature_data.pop('species')\n",
    "le = preprocessing.LabelEncoder()\n",
    "train_labels = le.fit(train_labels).transform(train_labels) \n",
    "\n",
    "# standardize the data by setting the mean to 0 and std to 1\n",
    "scaler = StandardScaler().fit(train_feature_data)\n",
    "train_feature_data = scaler.transform(train_feature_data)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(train_feature_data, train_labels, test_size=.1, random_state=2, stratify = train_labels)\n",
    "y_train = (np.arange(99) == y_train[:,None]).astype(np.float32)\n",
    "y_val = (np.arange(99) == y_val[:,None]).astype(np.float32)\n",
    "\n",
    "X_train = X_train.astype(np.float32)\n",
    "X_val = X_val.astype(np.float32)\n",
    "\n",
    "test_feature_id = test_feature_data.pop(\"id\")\n",
    "test_feature_data = scaler.transform(test_feature_data)\n",
    "test_feature_data = test_feature_data.astype(np.float32)\n",
    "\n",
    "\n",
    "print(\"Training Data\", X_train.shape, y_train.shape)\n",
    "print(\"Validated Data\", X_val.shape, y_val.shape)\n",
    "print(\"Test Data\", test_feature_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def accuracy(predictions, labels):\n",
    "    return (100.0 * np.sum(np.argmax(predictions, 1) == np.argmax(labels, 1))\n",
    "            / predictions.shape[0])\n",
    "\n",
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.01)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "\n",
    "split_by_half = lambda x,k : int(x/2**k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Quercus_Palustris' 'Quercus_Shumardii']\n",
      "['Lithocarpus_Cleistocarpus' 'Lithocarpus_Edulis']\n",
      "['Eucalyptus_Glaucescens' 'Eucalyptus_Neglecta']\n",
      "['Quercus_Canariensis' 'Quercus_Pubescens']\n",
      "['Quercus_Kewensis' 'Quercus_Castaneifolia']\n",
      "['Quercus_Ilex' 'Quercus_Greggii']\n"
     ]
    }
   ],
   "source": [
    "print(le.inverse_transform([71, 80]))\n",
    "print(le.inverse_transform([37, 38]))\n",
    "print(le.inverse_transform([28, 29]))\n",
    "print(le.inverse_transform([54, 75]))\n",
    "print(le.inverse_transform([69, 55]))\n",
    "print(le.inverse_transform([66, 64]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size = 662\n",
    "hidden_nodes = 1024\n",
    "lamb_reg = 0.0\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "\n",
    "    # Input data.\n",
    "    tf_train_dataset = tf.placeholder(tf.float32, shape=(batch_size, 192))\n",
    "    tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, 99))\n",
    "    tf_valid_dataset = tf.constant(X_val)\n",
    "    tf_valid_labels = tf.constant(y_val)\n",
    "    tf_test_dataset = tf.constant(test_feature_data)\n",
    "\n",
    "    # Variables.\n",
    "    layer1_weights = weight_variable([192, hidden_nodes])\n",
    "    layer1_biases = bias_variable([hidden_nodes])\n",
    "    layer4_weights = weight_variable([hidden_nodes, 99])\n",
    "    layer4_biases = bias_variable([99])\n",
    "    \n",
    "    keep_prob = tf.placeholder(\"float\")\n",
    "    \n",
    "    # Model with dropout\n",
    "    def model(data, proba=keep_prob):\n",
    "        layer1 = tf.matmul(data, layer1_weights) + layer1_biases\n",
    "        hidden1 = tf.nn.dropout(tf.nn.relu(layer1), proba)  # dropout on hidden layer\n",
    "        return tf.matmul(hidden1, layer4_weights) + layer4_biases\n",
    "    \n",
    "    # Training computation.\n",
    "    logits = model(tf_train_dataset, keep_prob)\n",
    "    \n",
    "    # loss = tf.reduce_sum(tf.multiply(tf.log(tf.clip_by_value(tf.nn.softmax(logits), 1e-10, 1.0)), tf_train_labels))/-32.0\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits, tf_train_labels))\n",
    "   \n",
    "    regularizers = (tf.nn.l2_loss(layer1_weights) + tf.nn.l2_loss(layer1_biases) + \\\n",
    "                    tf.nn.l2_loss(layer4_weights) + tf.nn.l2_loss(layer4_biases))\n",
    "\n",
    "    # Add the regularization term to the loss.\n",
    "    loss = tf.reduce_mean(loss + lamb_reg * regularizers)\n",
    "    \n",
    "    # Optimizer.\n",
    "    optimizer = tf.train.RMSPropOptimizer(1e-4).minimize(loss)\n",
    "\n",
    "    \n",
    "    # Predictions for the training, validation, and test data.\n",
    "    train_prediction = tf.nn.softmax(logits)\n",
    "    valid_prediction = tf.nn.softmax(model(tf_valid_dataset, 1.0))\n",
    "    \n",
    "    # loss_v = tf.reduce_sum(tf.multiply(tf.log(tf.clip_by_value(valid_prediction, 1e-10, 1.0)), tf_valid_labels))/-(99.0*3)\n",
    "    loss_v = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(model(tf_valid_dataset,1.0), tf_valid_labels))\n",
    "    \n",
    "    test_prediction = tf.nn.softmax(model(tf_test_dataset, 1.0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Re-define the function to include the keep probability\n",
    "\n",
    "def run_session(num_epochs, name, k_prob=1.0):\n",
    "\n",
    "    with tf.Session(graph=graph) as session:\n",
    "        merged = tf.merge_all_summaries()  \n",
    "        writer = tf.train.SummaryWriter(\"/tmp/tensorflowlogs\", session.graph)\n",
    "        tf.initialize_all_variables().run()\n",
    "        print(\"Initialized\")\n",
    "        for epoch in range(num_epochs):\n",
    "            offset = (epoch * batch_size) % (y_train.shape[0] - batch_size)\n",
    "            batch_data = X_train[offset:(offset + batch_size), :]\n",
    "            batch_labels = y_train[offset:(offset + batch_size), :]\n",
    "            feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels, keep_prob : k_prob}\n",
    "            _, l, predictions, l_v = session.run([optimizer, loss, train_prediction, loss_v], feed_dict=feed_dict)\n",
    "            if (epoch % 500 == 0):\n",
    "                print(\"Minibatch loss at epoch {}: {}\".format(epoch, l))\n",
    "                print(\"Validation loss at epoch {}: {}\".format(epoch, l_v))\n",
    "                print(\"Minibatch accuracy: {:.1f}\".format(accuracy(predictions, batch_labels)))\n",
    "                print(\"Validation accuracy: {:.1f}\".format(accuracy(valid_prediction.eval(), y_val)))\n",
    "        \n",
    "        test_prob = test_prediction.eval()\n",
    "        return test_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-157-b2367149e2da>:6 in run_session.: merge_all_summaries (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.merge_all.\n",
      "WARNING:tensorflow:From <ipython-input-157-b2367149e2da>:7 in run_session.: SummaryWriter.__init__ (from tensorflow.python.training.summary_io) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.FileWriter. The interface and behavior is the same; this is just a rename.\n",
      "WARNING:tensorflow:From <ipython-input-157-b2367149e2da>:8 in run_session.: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "Initialized\n",
      "Minibatch loss at epoch 0: 4.59370231628418\n",
      "Validation loss at epoch 0: 4.59503698348999\n",
      "Minibatch accuracy: 0.6\n",
      "Validation accuracy: 0.0\n",
      "Minibatch loss at epoch 500: 0.08406969904899597\n",
      "Validation loss at epoch 500: 0.13460473716259003\n",
      "Minibatch accuracy: 99.8\n",
      "Validation accuracy: 99.0\n",
      "Minibatch loss at epoch 1000: 0.0011797471670433879\n",
      "Validation loss at epoch 1000: 0.013119995594024658\n",
      "Minibatch accuracy: 100.0\n",
      "Validation accuracy: 100.0\n",
      "Minibatch loss at epoch 1500: 0.0001918996131280437\n",
      "Validation loss at epoch 1500: 0.006283221300691366\n",
      "Minibatch accuracy: 100.0\n",
      "Validation accuracy: 100.0\n",
      "Minibatch loss at epoch 2000: 0.0001024752200464718\n",
      "Validation loss at epoch 2000: 0.004507883917540312\n",
      "Minibatch accuracy: 100.0\n",
      "Validation accuracy: 100.0\n",
      "Minibatch loss at epoch 2500: 0.00010628056770656258\n",
      "Validation loss at epoch 2500: 0.0038606112357228994\n",
      "Minibatch accuracy: 100.0\n",
      "Validation accuracy: 100.0\n",
      "Minibatch loss at epoch 3000: 4.857066596741788e-05\n",
      "Validation loss at epoch 3000: 0.0034371167421340942\n",
      "Minibatch accuracy: 100.0\n",
      "Validation accuracy: 100.0\n",
      "Minibatch loss at epoch 3500: 4.8225738282781094e-05\n",
      "Validation loss at epoch 3500: 0.0030566358473151922\n",
      "Minibatch accuracy: 100.0\n",
      "Validation accuracy: 100.0\n",
      "Minibatch loss at epoch 4000: 4.548279684968293e-05\n",
      "Validation loss at epoch 4000: 0.002784735755994916\n",
      "Minibatch accuracy: 100.0\n",
      "Validation accuracy: 100.0\n",
      "Minibatch loss at epoch 4500: 3.341135015944019e-05\n",
      "Validation loss at epoch 4500: 0.0024424358271062374\n",
      "Minibatch accuracy: 100.0\n",
      "Validation accuracy: 100.0\n",
      "Minibatch loss at epoch 5000: 3.575132359401323e-05\n",
      "Validation loss at epoch 5000: 0.0024412276688963175\n",
      "Minibatch accuracy: 100.0\n",
      "Validation accuracy: 100.0\n",
      "Minibatch loss at epoch 5500: 1.8835640730685554e-05\n",
      "Validation loss at epoch 5500: 0.0023404303938150406\n",
      "Minibatch accuracy: 100.0\n",
      "Validation accuracy: 100.0\n",
      "Minibatch loss at epoch 6000: 2.819764631567523e-05\n",
      "Validation loss at epoch 6000: 0.002207846147939563\n",
      "Minibatch accuracy: 100.0\n",
      "Validation accuracy: 100.0\n",
      "Minibatch loss at epoch 6500: 1.635222179174889e-05\n",
      "Validation loss at epoch 6500: 0.0021512298844754696\n",
      "Minibatch accuracy: 100.0\n",
      "Validation accuracy: 100.0\n",
      "Minibatch loss at epoch 7000: 1.596323818375822e-05\n",
      "Validation loss at epoch 7000: 0.0019604528788477182\n",
      "Minibatch accuracy: 100.0\n",
      "Validation accuracy: 100.0\n",
      "Minibatch loss at epoch 7500: 1.509985941083869e-05\n",
      "Validation loss at epoch 7500: 0.0018573773559182882\n",
      "Minibatch accuracy: 100.0\n",
      "Validation accuracy: 100.0\n",
      "Minibatch loss at epoch 8000: 1.1723332136170939e-05\n",
      "Validation loss at epoch 8000: 0.0019328987691551447\n",
      "Minibatch accuracy: 100.0\n",
      "Validation accuracy: 100.0\n",
      "Minibatch loss at epoch 8500: 1.4413008102565072e-05\n",
      "Validation loss at epoch 8500: 0.0018375675426796079\n",
      "Minibatch accuracy: 100.0\n",
      "Validation accuracy: 100.0\n",
      "Minibatch loss at epoch 9000: 1.5467287084902637e-05\n",
      "Validation loss at epoch 9000: 0.0017942650010809302\n",
      "Minibatch accuracy: 100.0\n",
      "Validation accuracy: 100.0\n",
      "Minibatch loss at epoch 9500: 1.1621195881161839e-05\n",
      "Validation loss at epoch 9500: 0.0016972363227978349\n",
      "Minibatch accuracy: 100.0\n",
      "Validation accuracy: 100.0\n",
      "Minibatch loss at epoch 10000: 1.0313018719898537e-05\n",
      "Validation loss at epoch 10000: 0.0017267935909330845\n",
      "Minibatch accuracy: 100.0\n",
      "Validation accuracy: 100.0\n",
      "Minibatch loss at epoch 10500: 1.118149702961091e-05\n",
      "Validation loss at epoch 10500: 0.0017529650358483195\n",
      "Minibatch accuracy: 100.0\n",
      "Validation accuracy: 100.0\n",
      "Minibatch loss at epoch 11000: 1.2621228961506858e-05\n",
      "Validation loss at epoch 11000: 0.0015774990897625685\n",
      "Minibatch accuracy: 100.0\n",
      "Validation accuracy: 100.0\n",
      "Minibatch loss at epoch 11500: 6.505457804450998e-06\n",
      "Validation loss at epoch 11500: 0.001601921976543963\n",
      "Minibatch accuracy: 100.0\n",
      "Validation accuracy: 100.0\n",
      "Minibatch loss at epoch 12000: 1.6207424778258428e-05\n",
      "Validation loss at epoch 12000: 0.0015836466336622834\n",
      "Minibatch accuracy: 100.0\n",
      "Validation accuracy: 100.0\n",
      "Minibatch loss at epoch 12500: 7.10997665009927e-06\n",
      "Validation loss at epoch 12500: 0.001519314362667501\n",
      "Minibatch accuracy: 100.0\n",
      "Validation accuracy: 100.0\n",
      "Minibatch loss at epoch 13000: 7.011649358901195e-06\n",
      "Validation loss at epoch 13000: 0.0015012453077360988\n",
      "Minibatch accuracy: 100.0\n",
      "Validation accuracy: 100.0\n",
      "Minibatch loss at epoch 13500: 8.44383794174064e-06\n",
      "Validation loss at epoch 13500: 0.0015658789779990911\n",
      "Minibatch accuracy: 100.0\n",
      "Validation accuracy: 100.0\n",
      "Minibatch loss at epoch 14000: 8.702178092789836e-06\n",
      "Validation loss at epoch 14000: 0.0014905844582244754\n",
      "Minibatch accuracy: 100.0\n",
      "Validation accuracy: 100.0\n",
      "Minibatch loss at epoch 14500: 8.732063179195393e-06\n",
      "Validation loss at epoch 14500: 0.0013520159991458058\n",
      "Minibatch accuracy: 100.0\n",
      "Validation accuracy: 100.0\n",
      "Minibatch loss at epoch 15000: 6.778281658625929e-06\n",
      "Validation loss at epoch 15000: 0.0013430704129859805\n",
      "Minibatch accuracy: 100.0\n",
      "Validation accuracy: 100.0\n",
      "Minibatch loss at epoch 15500: 5.696633252227912e-06\n",
      "Validation loss at epoch 15500: 0.001355918007902801\n",
      "Minibatch accuracy: 100.0\n",
      "Validation accuracy: 100.0\n",
      "Minibatch loss at epoch 16000: 5.99886561758467e-06\n",
      "Validation loss at epoch 16000: 0.0013696319656446576\n",
      "Minibatch accuracy: 100.0\n",
      "Validation accuracy: 100.0\n",
      "Minibatch loss at epoch 16500: 4.410648671182571e-06\n",
      "Validation loss at epoch 16500: 0.001312695792876184\n",
      "Minibatch accuracy: 100.0\n",
      "Validation accuracy: 100.0\n",
      "Minibatch loss at epoch 17000: 8.034699931158684e-06\n",
      "Validation loss at epoch 17000: 0.001285392907448113\n",
      "Minibatch accuracy: 100.0\n",
      "Validation accuracy: 100.0\n",
      "Minibatch loss at epoch 17500: 9.775138096301816e-06\n",
      "Validation loss at epoch 17500: 0.0013116063782945275\n",
      "Minibatch accuracy: 100.0\n",
      "Validation accuracy: 100.0\n",
      "Minibatch loss at epoch 18000: 5.57511521037668e-06\n",
      "Validation loss at epoch 18000: 0.0013082921504974365\n",
      "Minibatch accuracy: 100.0\n",
      "Validation accuracy: 100.0\n",
      "Minibatch loss at epoch 18500: 4.306356458982918e-06\n",
      "Validation loss at epoch 18500: 0.0013091450091451406\n",
      "Minibatch accuracy: 100.0\n",
      "Validation accuracy: 100.0\n",
      "Minibatch loss at epoch 19000: 4.434193215274718e-06\n",
      "Validation loss at epoch 19000: 0.001350767444819212\n",
      "Minibatch accuracy: 100.0\n",
      "Validation accuracy: 100.0\n",
      "Minibatch loss at epoch 19500: 7.529785762017127e-06\n",
      "Validation loss at epoch 19500: 0.0013065955135971308\n",
      "Minibatch accuracy: 100.0\n",
      "Validation accuracy: 100.0\n"
     ]
    }
   ],
   "source": [
    "test_prob = run_session(20000, \"Deep_NN\", 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Acer_Capillipes</th>\n",
       "      <th>Acer_Circinatum</th>\n",
       "      <th>Acer_Mono</th>\n",
       "      <th>Acer_Opalus</th>\n",
       "      <th>Acer_Palmatum</th>\n",
       "      <th>Acer_Pictum</th>\n",
       "      <th>Acer_Platanoids</th>\n",
       "      <th>Acer_Rubrum</th>\n",
       "      <th>Acer_Rufinerve</th>\n",
       "      <th>Acer_Saccharinum</th>\n",
       "      <th>...</th>\n",
       "      <th>Salix_Fragilis</th>\n",
       "      <th>Salix_Intergra</th>\n",
       "      <th>Sorbus_Aria</th>\n",
       "      <th>Tilia_Oliveri</th>\n",
       "      <th>Tilia_Platyphyllos</th>\n",
       "      <th>Tilia_Tomentosa</th>\n",
       "      <th>Ulmus_Bergmanniana</th>\n",
       "      <th>Viburnum_Tinus</th>\n",
       "      <th>Viburnum_x_Rhytidophylloides</th>\n",
       "      <th>Zelkova_Serrata</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1576</th>\n",
       "      <td>2.440899e-10</td>\n",
       "      <td>9.999995e-01</td>\n",
       "      <td>8.831962e-14</td>\n",
       "      <td>4.768233e-17</td>\n",
       "      <td>2.955674e-07</td>\n",
       "      <td>1.188586e-13</td>\n",
       "      <td>1.947139e-14</td>\n",
       "      <td>2.422856e-10</td>\n",
       "      <td>1.384369e-08</td>\n",
       "      <td>1.447734e-09</td>\n",
       "      <td>...</td>\n",
       "      <td>2.215762e-12</td>\n",
       "      <td>1.992084e-16</td>\n",
       "      <td>4.124587e-13</td>\n",
       "      <td>1.252392e-14</td>\n",
       "      <td>7.429296e-16</td>\n",
       "      <td>1.154957e-12</td>\n",
       "      <td>7.869796e-10</td>\n",
       "      <td>2.169862e-18</td>\n",
       "      <td>1.437015e-14</td>\n",
       "      <td>8.275723e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1577</th>\n",
       "      <td>4.083067e-10</td>\n",
       "      <td>7.456544e-10</td>\n",
       "      <td>1.097664e-16</td>\n",
       "      <td>6.771465e-10</td>\n",
       "      <td>8.047896e-14</td>\n",
       "      <td>8.158166e-18</td>\n",
       "      <td>6.095036e-12</td>\n",
       "      <td>2.575843e-07</td>\n",
       "      <td>1.658736e-07</td>\n",
       "      <td>8.135807e-14</td>\n",
       "      <td>...</td>\n",
       "      <td>4.091379e-13</td>\n",
       "      <td>8.341479e-17</td>\n",
       "      <td>1.472110e-07</td>\n",
       "      <td>1.347312e-12</td>\n",
       "      <td>9.415825e-09</td>\n",
       "      <td>1.759933e-08</td>\n",
       "      <td>4.895080e-12</td>\n",
       "      <td>7.492896e-18</td>\n",
       "      <td>1.220798e-13</td>\n",
       "      <td>1.092134e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1579</th>\n",
       "      <td>3.385547e-12</td>\n",
       "      <td>7.436422e-13</td>\n",
       "      <td>7.781795e-16</td>\n",
       "      <td>1.848521e-16</td>\n",
       "      <td>5.576487e-10</td>\n",
       "      <td>6.263753e-10</td>\n",
       "      <td>4.617105e-17</td>\n",
       "      <td>4.457102e-14</td>\n",
       "      <td>5.285590e-16</td>\n",
       "      <td>2.758280e-08</td>\n",
       "      <td>...</td>\n",
       "      <td>8.612141e-18</td>\n",
       "      <td>1.842578e-18</td>\n",
       "      <td>4.978316e-12</td>\n",
       "      <td>7.207074e-14</td>\n",
       "      <td>1.402834e-11</td>\n",
       "      <td>9.493672e-21</td>\n",
       "      <td>7.986348e-18</td>\n",
       "      <td>6.301556e-15</td>\n",
       "      <td>1.530689e-11</td>\n",
       "      <td>1.159556e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1580</th>\n",
       "      <td>1.854899e-16</td>\n",
       "      <td>2.213022e-17</td>\n",
       "      <td>2.629771e-11</td>\n",
       "      <td>7.787225e-16</td>\n",
       "      <td>2.444330e-15</td>\n",
       "      <td>8.753764e-19</td>\n",
       "      <td>9.019534e-12</td>\n",
       "      <td>5.152140e-12</td>\n",
       "      <td>1.232334e-17</td>\n",
       "      <td>2.369852e-20</td>\n",
       "      <td>...</td>\n",
       "      <td>3.160817e-10</td>\n",
       "      <td>1.943864e-11</td>\n",
       "      <td>3.129738e-20</td>\n",
       "      <td>6.482206e-12</td>\n",
       "      <td>1.285599e-20</td>\n",
       "      <td>2.639021e-15</td>\n",
       "      <td>1.332293e-16</td>\n",
       "      <td>4.845224e-16</td>\n",
       "      <td>1.333509e-22</td>\n",
       "      <td>3.582541e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1583</th>\n",
       "      <td>1.096192e-20</td>\n",
       "      <td>1.420207e-14</td>\n",
       "      <td>3.296923e-12</td>\n",
       "      <td>7.646984e-16</td>\n",
       "      <td>7.315460e-13</td>\n",
       "      <td>4.304280e-09</td>\n",
       "      <td>5.703745e-09</td>\n",
       "      <td>4.314401e-15</td>\n",
       "      <td>1.262867e-17</td>\n",
       "      <td>2.398561e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>3.857383e-16</td>\n",
       "      <td>4.660028e-18</td>\n",
       "      <td>5.793973e-17</td>\n",
       "      <td>8.932258e-15</td>\n",
       "      <td>1.903239e-15</td>\n",
       "      <td>1.095350e-17</td>\n",
       "      <td>2.922866e-17</td>\n",
       "      <td>1.916730e-14</td>\n",
       "      <td>5.947094e-18</td>\n",
       "      <td>7.070727e-12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 99 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Acer_Capillipes  Acer_Circinatum     Acer_Mono   Acer_Opalus  \\\n",
       "id                                                                   \n",
       "1576     2.440899e-10     9.999995e-01  8.831962e-14  4.768233e-17   \n",
       "1577     4.083067e-10     7.456544e-10  1.097664e-16  6.771465e-10   \n",
       "1579     3.385547e-12     7.436422e-13  7.781795e-16  1.848521e-16   \n",
       "1580     1.854899e-16     2.213022e-17  2.629771e-11  7.787225e-16   \n",
       "1583     1.096192e-20     1.420207e-14  3.296923e-12  7.646984e-16   \n",
       "\n",
       "      Acer_Palmatum   Acer_Pictum  Acer_Platanoids   Acer_Rubrum  \\\n",
       "id                                                                 \n",
       "1576   2.955674e-07  1.188586e-13     1.947139e-14  2.422856e-10   \n",
       "1577   8.047896e-14  8.158166e-18     6.095036e-12  2.575843e-07   \n",
       "1579   5.576487e-10  6.263753e-10     4.617105e-17  4.457102e-14   \n",
       "1580   2.444330e-15  8.753764e-19     9.019534e-12  5.152140e-12   \n",
       "1583   7.315460e-13  4.304280e-09     5.703745e-09  4.314401e-15   \n",
       "\n",
       "      Acer_Rufinerve  Acer_Saccharinum       ...         Salix_Fragilis  \\\n",
       "id                                           ...                          \n",
       "1576    1.384369e-08      1.447734e-09       ...           2.215762e-12   \n",
       "1577    1.658736e-07      8.135807e-14       ...           4.091379e-13   \n",
       "1579    5.285590e-16      2.758280e-08       ...           8.612141e-18   \n",
       "1580    1.232334e-17      2.369852e-20       ...           3.160817e-10   \n",
       "1583    1.262867e-17      2.398561e-15       ...           3.857383e-16   \n",
       "\n",
       "      Salix_Intergra   Sorbus_Aria  Tilia_Oliveri  Tilia_Platyphyllos  \\\n",
       "id                                                                      \n",
       "1576    1.992084e-16  4.124587e-13   1.252392e-14        7.429296e-16   \n",
       "1577    8.341479e-17  1.472110e-07   1.347312e-12        9.415825e-09   \n",
       "1579    1.842578e-18  4.978316e-12   7.207074e-14        1.402834e-11   \n",
       "1580    1.943864e-11  3.129738e-20   6.482206e-12        1.285599e-20   \n",
       "1583    4.660028e-18  5.793973e-17   8.932258e-15        1.903239e-15   \n",
       "\n",
       "      Tilia_Tomentosa  Ulmus_Bergmanniana  Viburnum_Tinus  \\\n",
       "id                                                          \n",
       "1576     1.154957e-12        7.869796e-10    2.169862e-18   \n",
       "1577     1.759933e-08        4.895080e-12    7.492896e-18   \n",
       "1579     9.493672e-21        7.986348e-18    6.301556e-15   \n",
       "1580     2.639021e-15        1.332293e-16    4.845224e-16   \n",
       "1583     1.095350e-17        2.922866e-17    1.916730e-14   \n",
       "\n",
       "      Viburnum_x_Rhytidophylloides  Zelkova_Serrata  \n",
       "id                                                   \n",
       "1576                  1.437015e-14     8.275723e-08  \n",
       "1577                  1.220798e-13     1.092134e-07  \n",
       "1579                  1.530689e-11     1.159556e-09  \n",
       "1580                  1.333509e-22     3.582541e-15  \n",
       "1583                  5.947094e-18     7.070727e-12  \n",
       "\n",
       "[5 rows x 99 columns]"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_submit = pd.DataFrame(test_prob, index=test_feature_id,columns=le.inverse_transform(range(99)))\n",
    "\n",
    "fp = open('submit.csv', 'w')\n",
    "fp.write(test_submit.to_csv())\n",
    "\n",
    "test_submit.tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-5-ab39e78ab355>:28 in run_session.: merge_all_summaries (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.merge_all.\n",
      "WARNING:tensorflow:From <ipython-input-5-ab39e78ab355>:29 in run_session.: SummaryWriter.__init__ (from tensorflow.python.training.summary_io) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.FileWriter. The interface and behavior is the same; this is just a rename.\n",
      "WARNING:tensorflow:From <ipython-input-5-ab39e78ab355>:30 in run_session.: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "Initialized\n",
      "Minibatch loss at epoch 0: 4.602806568145752\n",
      "Validation loss at epoch 0: 4.601140022277832\n",
      "Minibatch accuracy: 0.8\n",
      "Validation accuracy: 0.0\n",
      "Minibatch loss at epoch 10000: 7.220596216939157e-06\n",
      "Validation loss at epoch 10000: 0.0343179851770401\n",
      "Minibatch accuracy: 100.0\n",
      "Validation accuracy: 99.0\n",
      "10\n",
      "WARNING:tensorflow:From <ipython-input-5-ab39e78ab355>:28 in run_session.: merge_all_summaries (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.merge_all.\n",
      "WARNING:tensorflow:From <ipython-input-5-ab39e78ab355>:29 in run_session.: SummaryWriter.__init__ (from tensorflow.python.training.summary_io) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.FileWriter. The interface and behavior is the same; this is just a rename.\n",
      "WARNING:tensorflow:From <ipython-input-5-ab39e78ab355>:30 in run_session.: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "Initialized\n",
      "Minibatch loss at epoch 0: 4.594104766845703\n",
      "Validation loss at epoch 0: 4.594125270843506\n",
      "Minibatch accuracy: 1.5\n",
      "Validation accuracy: 1.0\n",
      "Minibatch loss at epoch 10000: 1.0206143087998498e-05\n",
      "Validation loss at epoch 10000: 0.004739890340715647\n",
      "Minibatch accuracy: 100.0\n",
      "Validation accuracy: 100.0\n",
      "11\n",
      "WARNING:tensorflow:From <ipython-input-5-ab39e78ab355>:28 in run_session.: merge_all_summaries (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.merge_all.\n",
      "WARNING:tensorflow:From <ipython-input-5-ab39e78ab355>:29 in run_session.: SummaryWriter.__init__ (from tensorflow.python.training.summary_io) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.FileWriter. The interface and behavior is the same; this is just a rename.\n",
      "WARNING:tensorflow:From <ipython-input-5-ab39e78ab355>:30 in run_session.: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "Initialized\n",
      "Minibatch loss at epoch 0: 4.596772193908691\n",
      "Validation loss at epoch 0: 4.595419406890869\n",
      "Minibatch accuracy: 1.2\n",
      "Validation accuracy: 1.0\n",
      "Minibatch loss at epoch 10000: 8.02330396254547e-06\n",
      "Validation loss at epoch 10000: 0.00711124949157238\n",
      "Minibatch accuracy: 100.0\n",
      "Validation accuracy: 100.0\n",
      "12\n",
      "WARNING:tensorflow:From <ipython-input-5-ab39e78ab355>:28 in run_session.: merge_all_summaries (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.merge_all.\n",
      "WARNING:tensorflow:From <ipython-input-5-ab39e78ab355>:29 in run_session.: SummaryWriter.__init__ (from tensorflow.python.training.summary_io) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.FileWriter. The interface and behavior is the same; this is just a rename.\n",
      "WARNING:tensorflow:From <ipython-input-5-ab39e78ab355>:30 in run_session.: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "Initialized\n",
      "Minibatch loss at epoch 0: 4.591585159301758\n",
      "Validation loss at epoch 0: 4.594095230102539\n",
      "Minibatch accuracy: 1.1\n",
      "Validation accuracy: 0.0\n",
      "Minibatch loss at epoch 10000: 1.02084522950463e-05\n",
      "Validation loss at epoch 10000: 0.032827042043209076\n",
      "Minibatch accuracy: 100.0\n",
      "Validation accuracy: 99.0\n",
      "13\n",
      "WARNING:tensorflow:From <ipython-input-5-ab39e78ab355>:28 in run_session.: merge_all_summaries (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.merge_all.\n",
      "WARNING:tensorflow:From <ipython-input-5-ab39e78ab355>:29 in run_session.: SummaryWriter.__init__ (from tensorflow.python.training.summary_io) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.FileWriter. The interface and behavior is the same; this is just a rename.\n",
      "WARNING:tensorflow:From <ipython-input-5-ab39e78ab355>:30 in run_session.: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "Initialized\n",
      "Minibatch loss at epoch 0: 4.60150146484375\n",
      "Validation loss at epoch 0: 4.602437496185303\n",
      "Minibatch accuracy: 0.8\n",
      "Validation accuracy: 1.0\n",
      "Minibatch loss at epoch 10000: 8.753661859373096e-06\n",
      "Validation loss at epoch 10000: 0.0038858926855027676\n",
      "Minibatch accuracy: 100.0\n",
      "Validation accuracy: 100.0\n",
      "14\n",
      "WARNING:tensorflow:From <ipython-input-5-ab39e78ab355>:28 in run_session.: merge_all_summaries (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.merge_all.\n",
      "WARNING:tensorflow:From <ipython-input-5-ab39e78ab355>:29 in run_session.: SummaryWriter.__init__ (from tensorflow.python.training.summary_io) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.FileWriter. The interface and behavior is the same; this is just a rename.\n",
      "WARNING:tensorflow:From <ipython-input-5-ab39e78ab355>:30 in run_session.: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "Initialized\n",
      "Minibatch loss at epoch 0: 4.600350379943848\n",
      "Validation loss at epoch 0: 4.60122013092041\n",
      "Minibatch accuracy: 0.9\n",
      "Validation accuracy: 3.0\n",
      "Minibatch loss at epoch 10000: 9.195924576488324e-06\n",
      "Validation loss at epoch 10000: 0.0027349693700671196\n",
      "Minibatch accuracy: 100.0\n",
      "Validation accuracy: 100.0\n",
      "15\n",
      "WARNING:tensorflow:From <ipython-input-5-ab39e78ab355>:28 in run_session.: merge_all_summaries (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.merge_all.\n",
      "WARNING:tensorflow:From <ipython-input-5-ab39e78ab355>:29 in run_session.: SummaryWriter.__init__ (from tensorflow.python.training.summary_io) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.FileWriter. The interface and behavior is the same; this is just a rename.\n",
      "WARNING:tensorflow:From <ipython-input-5-ab39e78ab355>:30 in run_session.: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "Initialized\n",
      "Minibatch loss at epoch 0: 4.60250186920166\n",
      "Validation loss at epoch 0: 4.59674596786499\n",
      "Minibatch accuracy: 1.2\n",
      "Validation accuracy: 3.0\n",
      "Minibatch loss at epoch 10000: 1.0665212357707787e-05\n",
      "Validation loss at epoch 10000: 0.0016204708954319358\n",
      "Minibatch accuracy: 100.0\n",
      "Validation accuracy: 100.0\n",
      "16\n",
      "WARNING:tensorflow:From <ipython-input-5-ab39e78ab355>:28 in run_session.: merge_all_summaries (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.merge_all.\n",
      "WARNING:tensorflow:From <ipython-input-5-ab39e78ab355>:29 in run_session.: SummaryWriter.__init__ (from tensorflow.python.training.summary_io) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.FileWriter. The interface and behavior is the same; this is just a rename.\n",
      "WARNING:tensorflow:From <ipython-input-5-ab39e78ab355>:30 in run_session.: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "Initialized\n",
      "Minibatch loss at epoch 0: 4.6025896072387695\n",
      "Validation loss at epoch 0: 4.597416877746582\n",
      "Minibatch accuracy: 0.8\n",
      "Validation accuracy: 0.0\n",
      "Minibatch loss at epoch 10000: 9.74582235357957e-06\n",
      "Validation loss at epoch 10000: 0.006075182929635048\n",
      "Minibatch accuracy: 100.0\n",
      "Validation accuracy: 100.0\n",
      "17\n",
      "WARNING:tensorflow:From <ipython-input-5-ab39e78ab355>:28 in run_session.: merge_all_summaries (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.merge_all.\n",
      "WARNING:tensorflow:From <ipython-input-5-ab39e78ab355>:29 in run_session.: SummaryWriter.__init__ (from tensorflow.python.training.summary_io) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.FileWriter. The interface and behavior is the same; this is just a rename.\n",
      "WARNING:tensorflow:From <ipython-input-5-ab39e78ab355>:30 in run_session.: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "Initialized\n",
      "Minibatch loss at epoch 0: 4.594454765319824\n",
      "Validation loss at epoch 0: 4.5969343185424805\n",
      "Minibatch accuracy: 1.4\n",
      "Validation accuracy: 0.0\n",
      "Minibatch loss at epoch 10000: 8.406871529587079e-06\n",
      "Validation loss at epoch 10000: 0.05351821705698967\n",
      "Minibatch accuracy: 100.0\n",
      "Validation accuracy: 98.0\n",
      "18\n",
      "WARNING:tensorflow:From <ipython-input-5-ab39e78ab355>:28 in run_session.: merge_all_summaries (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.merge_all.\n",
      "WARNING:tensorflow:From <ipython-input-5-ab39e78ab355>:29 in run_session.: SummaryWriter.__init__ (from tensorflow.python.training.summary_io) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.FileWriter. The interface and behavior is the same; this is just a rename.\n",
      "WARNING:tensorflow:From <ipython-input-5-ab39e78ab355>:30 in run_session.: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "Initialized\n",
      "Minibatch loss at epoch 0: 4.598971366882324\n",
      "Validation loss at epoch 0: 4.598673343658447\n",
      "Minibatch accuracy: 1.1\n",
      "Validation accuracy: 1.0\n",
      "Minibatch loss at epoch 10000: 1.3391247193794698e-05\n",
      "Validation loss at epoch 10000: 0.04784734174609184\n",
      "Minibatch accuracy: 100.0\n",
      "Validation accuracy: 98.0\n",
      "19\n",
      "WARNING:tensorflow:From <ipython-input-5-ab39e78ab355>:28 in run_session.: merge_all_summaries (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.merge_all.\n",
      "WARNING:tensorflow:From <ipython-input-5-ab39e78ab355>:29 in run_session.: SummaryWriter.__init__ (from tensorflow.python.training.summary_io) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.FileWriter. The interface and behavior is the same; this is just a rename.\n",
      "WARNING:tensorflow:From <ipython-input-5-ab39e78ab355>:30 in run_session.: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "Initialized\n",
      "Minibatch loss at epoch 0: 4.597156524658203\n",
      "Validation loss at epoch 0: 4.596156120300293\n",
      "Minibatch accuracy: 0.8\n",
      "Validation accuracy: 0.0\n",
      "Minibatch loss at epoch 10000: 1.0134885087609291e-05\n",
      "Validation loss at epoch 10000: 0.05022295564413071\n",
      "Minibatch accuracy: 100.0\n",
      "Validation accuracy: 98.0\n",
      "20\n",
      "WARNING:tensorflow:From <ipython-input-5-ab39e78ab355>:28 in run_session.: merge_all_summaries (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.merge_all.\n",
      "WARNING:tensorflow:From <ipython-input-5-ab39e78ab355>:29 in run_session.: SummaryWriter.__init__ (from tensorflow.python.training.summary_io) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.FileWriter. The interface and behavior is the same; this is just a rename.\n",
      "WARNING:tensorflow:From <ipython-input-5-ab39e78ab355>:30 in run_session.: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "Initialized\n",
      "Minibatch loss at epoch 0: 4.5928263664245605\n",
      "Validation loss at epoch 0: 4.597990036010742\n",
      "Minibatch accuracy: 0.9\n",
      "Validation accuracy: 1.0\n",
      "Minibatch loss at epoch 10000: 8.955780685937498e-06\n",
      "Validation loss at epoch 10000: 0.061501264572143555\n",
      "Minibatch accuracy: 100.0\n",
      "Validation accuracy: 99.0\n",
      "21\n",
      "WARNING:tensorflow:From <ipython-input-5-ab39e78ab355>:28 in run_session.: merge_all_summaries (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.merge_all.\n",
      "WARNING:tensorflow:From <ipython-input-5-ab39e78ab355>:29 in run_session.: SummaryWriter.__init__ (from tensorflow.python.training.summary_io) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.FileWriter. The interface and behavior is the same; this is just a rename.\n",
      "WARNING:tensorflow:From <ipython-input-5-ab39e78ab355>:30 in run_session.: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "Initialized\n",
      "Minibatch loss at epoch 0: 4.595385551452637\n",
      "Validation loss at epoch 0: 4.596623420715332\n",
      "Minibatch accuracy: 1.4\n",
      "Validation accuracy: 3.0\n",
      "Minibatch loss at epoch 10000: 9.212173608830199e-06\n",
      "Validation loss at epoch 10000: 0.04534272477030754\n",
      "Minibatch accuracy: 100.0\n",
      "Validation accuracy: 99.0\n",
      "22\n",
      "WARNING:tensorflow:From <ipython-input-5-ab39e78ab355>:28 in run_session.: merge_all_summaries (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.merge_all.\n",
      "WARNING:tensorflow:From <ipython-input-5-ab39e78ab355>:29 in run_session.: SummaryWriter.__init__ (from tensorflow.python.training.summary_io) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.FileWriter. The interface and behavior is the same; this is just a rename.\n",
      "WARNING:tensorflow:From <ipython-input-5-ab39e78ab355>:30 in run_session.: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "Initialized\n",
      "Minibatch loss at epoch 0: 4.597507953643799\n",
      "Validation loss at epoch 0: 4.595132827758789\n",
      "Minibatch accuracy: 0.9\n",
      "Validation accuracy: 1.0\n",
      "Minibatch loss at epoch 10000: 1.1341748177073896e-05\n",
      "Validation loss at epoch 10000: 0.1210799440741539\n",
      "Minibatch accuracy: 100.0\n",
      "Validation accuracy: 98.0\n",
      "23\n",
      "WARNING:tensorflow:From <ipython-input-5-ab39e78ab355>:28 in run_session.: merge_all_summaries (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.merge_all.\n",
      "WARNING:tensorflow:From <ipython-input-5-ab39e78ab355>:29 in run_session.: SummaryWriter.__init__ (from tensorflow.python.training.summary_io) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.FileWriter. The interface and behavior is the same; this is just a rename.\n",
      "WARNING:tensorflow:From <ipython-input-5-ab39e78ab355>:30 in run_session.: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "Initialized\n",
      "Minibatch loss at epoch 0: 4.598247051239014\n",
      "Validation loss at epoch 0: 4.594901084899902\n",
      "Minibatch accuracy: 1.5\n",
      "Validation accuracy: 2.0\n",
      "Minibatch loss at epoch 10000: 9.279921869165264e-06\n",
      "Validation loss at epoch 10000: 0.0035447978880256414\n",
      "Minibatch accuracy: 100.0\n",
      "Validation accuracy: 100.0\n",
      "24\n",
      "WARNING:tensorflow:From <ipython-input-5-ab39e78ab355>:28 in run_session.: merge_all_summaries (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.merge_all.\n",
      "WARNING:tensorflow:From <ipython-input-5-ab39e78ab355>:29 in run_session.: SummaryWriter.__init__ (from tensorflow.python.training.summary_io) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.FileWriter. The interface and behavior is the same; this is just a rename.\n",
      "WARNING:tensorflow:From <ipython-input-5-ab39e78ab355>:30 in run_session.: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "Initialized\n",
      "Minibatch loss at epoch 0: 4.593693256378174\n",
      "Validation loss at epoch 0: 4.593856334686279\n",
      "Minibatch accuracy: 1.4\n",
      "Validation accuracy: 1.0\n",
      "Minibatch loss at epoch 10000: 8.457090189040173e-06\n",
      "Validation loss at epoch 10000: 0.03331471234560013\n",
      "Minibatch accuracy: 100.0\n",
      "Validation accuracy: 99.0\n",
      "25\n",
      "WARNING:tensorflow:From <ipython-input-5-ab39e78ab355>:28 in run_session.: merge_all_summaries (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.merge_all.\n",
      "WARNING:tensorflow:From <ipython-input-5-ab39e78ab355>:29 in run_session.: SummaryWriter.__init__ (from tensorflow.python.training.summary_io) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.FileWriter. The interface and behavior is the same; this is just a rename.\n",
      "WARNING:tensorflow:From <ipython-input-5-ab39e78ab355>:30 in run_session.: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "Initialized\n",
      "Minibatch loss at epoch 0: 4.5958571434021\n",
      "Validation loss at epoch 0: 4.595814228057861\n",
      "Minibatch accuracy: 0.9\n",
      "Validation accuracy: 0.0\n",
      "Minibatch loss at epoch 10000: 1.834049544413574e-05\n",
      "Validation loss at epoch 10000: 0.08237166702747345\n",
      "Minibatch accuracy: 100.0\n",
      "Validation accuracy: 97.0\n",
      "26\n",
      "WARNING:tensorflow:From <ipython-input-5-ab39e78ab355>:28 in run_session.: merge_all_summaries (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.merge_all.\n",
      "WARNING:tensorflow:From <ipython-input-5-ab39e78ab355>:29 in run_session.: SummaryWriter.__init__ (from tensorflow.python.training.summary_io) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.FileWriter. The interface and behavior is the same; this is just a rename.\n",
      "WARNING:tensorflow:From <ipython-input-5-ab39e78ab355>:30 in run_session.: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "Initialized\n",
      "Minibatch loss at epoch 0: 4.5956807136535645\n",
      "Validation loss at epoch 0: 4.595305442810059\n",
      "Minibatch accuracy: 0.8\n",
      "Validation accuracy: 1.0\n",
      "Minibatch loss at epoch 10000: 8.594188329880126e-06\n",
      "Validation loss at epoch 10000: 0.006651509087532759\n",
      "Minibatch accuracy: 100.0\n",
      "Validation accuracy: 100.0\n",
      "27\n",
      "WARNING:tensorflow:From <ipython-input-5-ab39e78ab355>:28 in run_session.: merge_all_summaries (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.merge_all.\n",
      "WARNING:tensorflow:From <ipython-input-5-ab39e78ab355>:29 in run_session.: SummaryWriter.__init__ (from tensorflow.python.training.summary_io) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.FileWriter. The interface and behavior is the same; this is just a rename.\n",
      "WARNING:tensorflow:From <ipython-input-5-ab39e78ab355>:30 in run_session.: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "Initialized\n",
      "Minibatch loss at epoch 0: 4.593296051025391\n",
      "Validation loss at epoch 0: 4.595590591430664\n",
      "Minibatch accuracy: 1.7\n",
      "Validation accuracy: 2.0\n",
      "Minibatch loss at epoch 10000: 1.0590709280222654e-05\n",
      "Validation loss at epoch 10000: 0.09931056201457977\n",
      "Minibatch accuracy: 100.0\n",
      "Validation accuracy: 97.0\n",
      "28\n",
      "WARNING:tensorflow:From <ipython-input-5-ab39e78ab355>:28 in run_session.: merge_all_summaries (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.merge_all.\n",
      "WARNING:tensorflow:From <ipython-input-5-ab39e78ab355>:29 in run_session.: SummaryWriter.__init__ (from tensorflow.python.training.summary_io) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.FileWriter. The interface and behavior is the same; this is just a rename.\n",
      "WARNING:tensorflow:From <ipython-input-5-ab39e78ab355>:30 in run_session.: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "Initialized\n",
      "Minibatch loss at epoch 0: 4.595820903778076\n",
      "Validation loss at epoch 0: 4.595422267913818\n",
      "Minibatch accuracy: 1.1\n",
      "Validation accuracy: 2.0\n",
      "Minibatch loss at epoch 10000: 4.19504358433187e-05\n",
      "Validation loss at epoch 10000: 0.11770521104335785\n",
      "Minibatch accuracy: 100.0\n",
      "Validation accuracy: 98.0\n",
      "29\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import img_to_array, load_img, array_to_img\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def accuracy(predictions, labels):\n",
    "    return (100.0 * np.sum(np.argmax(predictions, 1) == np.argmax(labels, 1))\n",
    "            / predictions.shape[0])\n",
    "\n",
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.01)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "\n",
    "def run_session(num_epochs, name, k_prob=1.0):\n",
    "\n",
    "    with tf.Session(graph=graph) as session:\n",
    "        merged = tf.merge_all_summaries()  \n",
    "        writer = tf.train.SummaryWriter(\"/tmp/tensorflowlogs\", session.graph)\n",
    "        tf.initialize_all_variables().run()\n",
    "        print(\"Initialized\")\n",
    "        for epoch in range(num_epochs):\n",
    "            offset = (epoch * batch_size) % (y_train.shape[0] - batch_size)\n",
    "            batch_data = X_train[offset:(offset + batch_size), :]\n",
    "            batch_labels = y_train[offset:(offset + batch_size), :]\n",
    "            feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels, keep_prob : k_prob}\n",
    "            _, l, predictions, l_v = session.run([optimizer, loss, train_prediction, loss_v], feed_dict=feed_dict)\n",
    "            \n",
    "            if (epoch % 10000 == 0):\n",
    "                print(\"Minibatch loss at epoch {}: {}\".format(epoch, l))\n",
    "                print(\"Validation loss at epoch {}: {}\".format(epoch, l_v))\n",
    "                print(\"Minibatch accuracy: {:.1f}\".format(accuracy(predictions, batch_labels)))\n",
    "                print(\"Validation accuracy: {:.1f}\".format(accuracy(valid_prediction.eval(), y_val)))\n",
    "        \n",
    "        test_prob = test_prediction.eval()\n",
    "        return test_prob\n",
    "    \n",
    "    \n",
    "\n",
    "split_by_half = lambda x,k : int(x/2**k)\n",
    "\n",
    "\n",
    "train_feature_data = pd.read_csv(\"train.csv\")\n",
    "test_feature_data = pd.read_csv(\"test.csv\")\n",
    "\n",
    "ID = train_feature_data.pop(\"id\")\n",
    "\n",
    "train_labels = train_feature_data.pop('species')\n",
    "le = preprocessing.LabelEncoder()\n",
    "train_labels = le.fit(train_labels).transform(train_labels) \n",
    "\n",
    "# standardize the data by setting the mean to 0 and std to 1\n",
    "scaler = StandardScaler().fit(train_feature_data)\n",
    "train_feature_data = scaler.transform(train_feature_data)\n",
    "\n",
    "test_feature_id = test_feature_data.pop(\"id\")\n",
    "test_feature_data = scaler.transform(test_feature_data)\n",
    "test_feature_data = test_feature_data.astype(np.float32)\n",
    "\n",
    "for rdm in range(10, 30):\n",
    "    \n",
    "    X_train, X_val, y_train, y_val = train_test_split(train_feature_data, train_labels, test_size=.1, random_state=rdm, stratify = train_labels)\n",
    "    y_train = (np.arange(99) == y_train[:,None]).astype(np.float32)\n",
    "    y_val = (np.arange(99) == y_val[:,None]).astype(np.float32)\n",
    "\n",
    "    X_train = X_train.astype(np.float32)\n",
    "    X_val = X_val.astype(np.float32)\n",
    "\n",
    "    batch_size = 662\n",
    "    hidden_nodes = 1024\n",
    "    lamb_reg = 0.0\n",
    "\n",
    "    graph = tf.Graph()\n",
    "    with graph.as_default():\n",
    "\n",
    "        # Input data.\n",
    "        tf_train_dataset = tf.placeholder(tf.float32, shape=(batch_size, 192))\n",
    "        tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, 99))\n",
    "        tf_valid_dataset = tf.constant(X_val)\n",
    "        tf_valid_labels = tf.constant(y_val)\n",
    "        tf_test_dataset = tf.constant(test_feature_data)\n",
    "\n",
    "        # Variables.\n",
    "        layer1_weights = weight_variable([192, hidden_nodes])\n",
    "        layer1_biases = bias_variable([hidden_nodes])\n",
    "        layer4_weights = weight_variable([hidden_nodes, 99])\n",
    "        layer4_biases = bias_variable([99])\n",
    "\n",
    "        keep_prob = tf.placeholder(\"float\")\n",
    "\n",
    "        # Model with dropout\n",
    "        def model(data, proba=keep_prob):\n",
    "            layer1 = tf.matmul(data, layer1_weights) + layer1_biases\n",
    "            hidden1 = tf.nn.dropout(tf.nn.relu(layer1), proba)  # dropout on hidden layer\n",
    "            return tf.matmul(hidden1, layer4_weights) + layer4_biases\n",
    "\n",
    "        # Training computation.\n",
    "        logits = model(tf_train_dataset, keep_prob)\n",
    "\n",
    "        loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits, tf_train_labels))\n",
    "\n",
    "        regularizers = (tf.nn.l2_loss(layer1_weights) + tf.nn.l2_loss(layer1_biases) + \\\n",
    "                        tf.nn.l2_loss(layer4_weights) + tf.nn.l2_loss(layer4_biases))\n",
    "\n",
    "        # Add the regularization term to the loss.\n",
    "        loss = tf.reduce_mean(loss + lamb_reg * regularizers)\n",
    "\n",
    "        # Optimizer.\n",
    "        optimizer = tf.train.RMSPropOptimizer(1e-4).minimize(loss)\n",
    "\n",
    "\n",
    "        # Predictions for the training, validation, and test data.\n",
    "        train_prediction = tf.nn.softmax(logits)\n",
    "        valid_prediction = tf.nn.softmax(model(tf_valid_dataset, 1.0))\n",
    "\n",
    "        loss_v = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(model(tf_valid_dataset,1.0), tf_valid_labels))\n",
    "\n",
    "        test_prediction = tf.nn.softmax(model(tf_test_dataset, 1.0))\n",
    "        \n",
    "        test_prob = run_session(20000, \"Deep_NN\", 0.5)\n",
    "        \n",
    "        test_submit = pd.DataFrame(test_prob, index=test_feature_id, columns=le.inverse_transform(range(99)))\n",
    "        \n",
    "        print(rdm)\n",
    "        save_name = 'submit'+ str(rdm) + '.csv'\n",
    "        \n",
    "        fp = open(save_name, 'w')\n",
    "        fp.write(test_submit.to_csv())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn import preprocessing\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_feature_data = pd.read_csv(\"train.csv\")\n",
    "test_feature_data = pd.read_csv(\"test.csv\")\n",
    "\n",
    "need_species = [\"Cytisus_Battandieri\", \"Fagus_Sylvatica\", \"Populus_Adenopoda\"  ]  \n",
    "train_feature_data = train_feature_data.loc[train_feature_data[\"species\"].isin(need_species), : ]\n",
    "test_feature_data = test_feature_data.loc[test_feature_data[\"id\"] == 297, :]\n",
    "\n",
    "ID = train_feature_data.pop(\"id\")\n",
    "\n",
    "train_labels = train_feature_data.pop('species')\n",
    "le = preprocessing.LabelEncoder()\n",
    "train_labels = le.fit(train_labels).transform(train_labels) \n",
    "\n",
    "# standardize the data by setting the mean to 0 and std to 1\n",
    "scaler = StandardScaler().fit(train_feature_data)\n",
    "train_feature_data = scaler.transform(train_feature_data)\n",
    "\n",
    "\n",
    "test_feature_id = test_feature_data.pop(\"id\")\n",
    "test_feature_data = scaler.transform(test_feature_data)\n",
    "test_feature_data = test_feature_data.astype(np.float32)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'RandomForestClassifier' object has no attribute 'predict_prob'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-9d7b6835bab7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mprob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mleaf_rf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_feature_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;31m# print(le.inverse_transform(test_pred))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mprob\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'RandomForestClassifier' object has no attribute 'predict_prob'"
     ]
    }
   ],
   "source": [
    "leaf_rf = RandomForestClassifier(n_estimators=1000)\n",
    "leaf_rf.fit(train_feature_data, train_labels)\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(leaf_rf, train_feature_data, train_labels, cv=10)\n",
    "print(scores)\n",
    "\n",
    "prob = leaf_rf.predict_prob(test_feature_data)\n",
    "# print(le.inverse_transform(test_pred))\n",
    "prob"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
